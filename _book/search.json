[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"present online book provide review APIs may useful social scientists. Please start reading Introduction. material /developed various contributors can find contributor section corresponding github repository. interested contributing please check Section contribute github README.material licensed Apache License 2.0 license. draw authors material licenses may apply. extremely grateful feedback find errors please let us know.document generated R, RMarkdown Bookdown.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"project APIs Social Scientists: collaborative Review outcome seminar Computational Social Science (CSS) taught University Mannheim 2021. teaching seminar trouble finding short reviews APIs quick R-code examples. Fortunately, almost everyone participating seminar motivated enough write quick API review. Hopefully, resource help future students start diving different APIs.review different data- service-APIs may useful social scientists. chapters always include simple R code example well references social science research relied . idea provide short reviews max. 10 pages corresponding API code get started. chapter follows systematic set questions:data/service provided API? (+ provides ?)prerequisites access API (e.g., authentication)?simple API call look like?can access API R (httr + packages)? * social science research examples using API?","code":""},{"path":"introduction.html","id":"prerequesits-authentication","chapter":"1 Introduction","heading":"1.1 Prerequesits: Authentication","text":"lot APIs require authenticate API provider. underlying script review written way contains R chunks authentication, however visible examples (show placeholders recognize step need authenticate). chunks cases make use -called keys JSON format (e.g., service account key Google APIs). However cloning corresponding repository review result giving keys, hence order replicate API calls, generate use individual keys.","code":""},{"path":"introduction.html","id":"prerequesits-software-packages","chapter":"1 Introduction","heading":"1.2 Prerequesits: Software & packages","text":"code examples rely R different packages thereof. ’s probably easiest install one go. p_load() function (pacman package) checks whether packages installed. installed loaded.","code":"\nlibrary(pacman)\npacman::p_load(\n  dplyr, # needed for almost any chapter in this review\n  ggplot2, # e.g. CH5\n  tidytext, # comes in handy whenever text data is being pre-processed (CH2)\n  devtools, # to download any package from github (e.g., RCrowdTangle in CH4)\n  jsonlite, # import of JSON formats (e.g., CH4)\n  httr, # Tools for Working with URLs and HTTP (various chapters if an API call can me made via URL)\n  googleLanguageR, # allows different API calls for languga processing (CH2, CH3)\n  RCrowdTangle, #CH4\n  googleway, #CH5\n  mapsapi, #CH5\n  stars, #CH5\n  httr,\n  WikipediR # CH12\n)\n\n# Move these installations before pacman?\ndevtools::install_github(\"quanteda/quanteda.corpora\")\ndevtools::install_github(\"cbpuschmann/RCrowdTangle\")"},{"path":"google-natural-language-api.html","id":"google-natural-language-api","chapter":"2 Google Natural Language API","heading":"2 Google Natural Language API","text":"Paul C. Bauer, Camille Landesvatter, Malte Söhren","code":""},{"path":"google-natural-language-api.html","id":"provided-servicesdata","chapter":"2 Google Natural Language API","heading":"2.1 Provided services/data","text":"data/service provided API?API provided Google.Google Cloud offers two Natural Language Products: AutoML Natural Language Natural Language API. See read two products one useful .\nshort, option 1, Auto Machine Learning (ML) Natural Language allows train new, custom model either classify text, extract entities detect sentiment. instance, provide already pre-labeled subset data API use train custom classifier. classifier hand classify analyze similar data .\nAPI review focuses option 2, Natural Language API. API uses pre-trained models analyze data. Put differently, instead providing pre-labeled subset data, normally provide API complete (unlabeled) data analyze.following requests available:Analyzing Sentiment (analyzeSentiment)Analyzing Entities (analyzeEntities)Analyzing Syntax (analyzeSyntax)Analyzing Entity Sentiment (analyzeEntitySentiment)Classifying Content (classifyText)demo API allows input text explore different classification capabilities can found .","code":""},{"path":"google-natural-language-api.html","id":"prerequesites","chapter":"2 Google Natural Language API","heading":"2.2 Prerequesites","text":"prerequisites access API (authentication)? prerequisite access Google Natural Language API Google Cloud Project. create need Google account log Google Cloud Platform (GCP). Within Google Cloud Platform, must enable Natural Language API respective Google Cloud Project .\nAdditionally, planning request Natural Language API outside Google Cloud environment (e.g., R) required use private (service account) key. can achieved creating service account turn allow download private key JSON file. create API key authentication within GCP, go APIs & Services > Credentials. provide example authenticate within Google Cloud Platform (Cloud Shell + API key) authenticate within R (authentication via JSON key file).","code":""},{"path":"google-natural-language-api.html","id":"simple-api-call","chapter":"2 Google Natural Language API","heading":"2.3 Simple API call","text":"simple API call look like?describe simple API call can made within Google Cloud Platform environment via Google Cloud Shell:activate Cloud Shell, inspect upper right-hand corner Google Cloud Platform Console click icon called “Activate Shell”. Google Cloud Shell command line environment running cloud.Via Cloud Shell command line, add individual API key environment variables, required called request.Via built-Editor Cloud Shell create JSON file (call instance ‘request.json’) text like perform analysis . Consider text can uploaded request (shown ) integrated Cloud Storage. Supported types text PLAIN_TEXT (shown ) HTML.sending data, pass curl command Cloud Shell command line refer (via @) request.json file previous step.Depending endpoint send request (: analyzeEntities) receive response many different insights text data.","code":"export API_KEY=<YOUR_API_KEY>{\n  \"document\":{\n    \"type\":\"PLAIN_TEXT\",\n    \"content\":\"Enjoy your vacation!\"\n  },\n  \"encodingType\": \"UTF8\"\n}curl \"https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}\" -s -X POST -H \"Content-Type: application/json\" --data-binary @request.json"},{"path":"google-natural-language-api.html","id":"api-access","chapter":"2 Google Natural Language API","heading":"2.4 API access","text":"can access API R (httr + packages)?input (.e., text data) one provides API often go beyond single word sentence. convenient way also produces insightful structured results (can directly perform analysis ) achieved using ‘googleLanguageR’ R package - package among options (examples review) allows calling Natural Language API:small example demonstrate .... authenticate Google Cloud Account within R.. authenticate Google Cloud Account within R.. analyze syntax exemplary twitter data (using twitter data two popular german politicians, (via Google Translation API)\nbeforehand also translated english).. analyze syntax exemplary twitter data (using twitter data two popular german politicians, (via Google Translation API)\nbeforehand also translated english).. extract terms nouns .. extract terms nouns .. plot nouns word cloud.. plot nouns word cloudStep 1: Load packageStep 2: AuthenticationStep 3: AnalysisStart loading text data. example, retrieve data inherit quanteda.corpora R package broader sense associated famous quanteda package.data choose download (‘data_corpus_guardian’) contains Guardian newspaper articles politics, economy, society international sections 2012 2016. See list even publicy available text corpora quanteda.corpora package.Note: Whenever choose work textual data, common procedure pre-process data via set certain transformations. instance, convert letters lower case, remove numbers punctuation, trim words word stem eventually remove -called stopwords. many tutorials (example ).retrieved prepared --analyzed (text) data, can now call API via function gl_nlp(). specify quantity interest (: analyzeSyntax). Depending specific argument make use (e.g., analyzeSyntax, analyzeSentiment, etc.) list information different characteristics text returned, e.g., sentences, tokens, tags tokens.Importantly, find list tokens inherit large list syntax_analysis. list stores two variables: content (contains token) tag (contains tag, e.g., verb noun). Let’s look first document.Now imagine interested nouns used Guardian Articels removing types words (e.g., adjectives, verbs, etc.). can simply filter using “tag”-list.Step 4: VisualizationFinally, can also plot nouns wordcloud using ggwordcloud package.\nFigure 2.1: Wordcloud nouns found within guardian articles\n","code":"\nlibrary(googleLanguageR)\nlibrary(tidyverse)\nlibrary(tm)#stopwords\ngl_auth(\"./your-key.json\")\n# Download and store corpus\nguardian_corpus <- quanteda.corpora::download(\"data_corpus_guardian\")\n\n# Keep text only from the corpus\ntext <- guardian_corpus[[\"documents\"]][[\"texts\"]]\n\n# For demonstration purposes, subset the text data to 20 observations only\ntext <- text[1:20]\n\n# Turn text into a data frame and add an identifier\ndf <- as.data.frame(text)\ndf <- tibble::rowid_to_column(df, \"ID\")\nsyntax_analysis <- gl_nlp(df$text, nlp_type = \"analyzeSyntax\")\nhead(syntax_analysis[[\"tokens\"]][[1]][,1:3])##       content beginOffset   tag\n## 1      London           0  NOUN\n## 2 masterclass           7  NOUN\n## 3          on          19   ADP\n## 4     climate          22  NOUN\n## 5      change          30  NOUN\n## 6           |          37 PUNCT\n# Add tokens from syntax analysis to original dataframe\ndf$tokens <- syntax_analysis[[\"tokens\"]]\n\n# Keep nouns only\ndf <- df %>% dplyr::mutate(nouns = map(tokens, \n                            ~ dplyr::filter(., tag == \"NOUN\"))) \n# Load package\nlibrary(ggwordcloud)\n# Create the data for the plot\ndata_plot <- df %>% \n  # only keep content variable\n  mutate(nouns = map(nouns, \n                            ~ select(., content))) %>% \n  # Write tokens in all rows into a single string\n  unnest(nouns) %>% # unnest tokens\n  # Unnest tokens\n  tidytext::unnest_tokens(output = word, input = content) %>% # generate a wordcloud\n  anti_join(tidytext::stop_words) %>%\n  dplyr::count(word) %>%\n  filter(n > 10) #only plot words that appear more than 10 times\n\n# Visualize in a word cloud\ndata_plot %>%\n  ggplot(aes(label = word, \n             size = n)) +\n  geom_text_wordcloud() +\n  scale_size_area(max_size = 10) +\n  theme_minimal()"},{"path":"google-natural-language-api.html","id":"social-science-examples","chapter":"2 Google Natural Language API","heading":"2.5 Social science examples","text":"social science research examples using API?Text--data become quite common approach social sciences (see e.g., @Grimmer2013-xe overview). usage Google’s Natural Language API however impression relatively unknown NLP among social scientists. Hence, want emphasize usefulness importance usage Google’s NLP API many research projects.However, considering making use , keep two things mind:might interpret using API “blackbox” approach (see @Dobbrick2021-iz recent developments “glass-box machine learning appraoches” text analysis) potentially standing way transparency replication (two important criteria good research?). However always possible perform robustness sensitivity analysis add version API one using.might interpret using API “blackbox” approach (see @Dobbrick2021-iz recent developments “glass-box machine learning appraoches” text analysis) potentially standing way transparency replication (two important criteria good research?). However always possible perform robustness sensitivity analysis add version API one using.depending large corpus text data, Google might charges money. However 5,000 units (.e., terms) different variants sentiment syntax analysis free. Check overview Google learn prices units . Generally, also consider pursuing CSS-related project GCP Products come useful, possibility achieve Google Cloud Research credits (see ).depending large corpus text data, Google might charges money. However 5,000 units (.e., terms) different variants sentiment syntax analysis free. Check overview Google learn prices units . Generally, also consider pursuing CSS-related project GCP Products come useful, possibility achieve Google Cloud Research credits (see ).","code":""},{"path":"google-translation-api.html","id":"google-translation-api","chapter":"3 Google Translation API","heading":"3 Google Translation API","text":"Paul C. Bauer, Camille Landesvatter","code":""},{"path":"google-translation-api.html","id":"provided-servicesdata-1","chapter":"3 Google Translation API","heading":"3.1 Provided services/data","text":"data/service provided API?API provided Google.Google’s Translation API translates texts one hundred languages. Note approach via API lot refined free version Googles’ translation website course comes useful text large scale needs translated (possibly longer complex content syntax). instance, can choose specify certain model improve translation (Neural Machine Translation vs. Phrase-Based Machine Translation).API limits three ways: characters per day, characters per 100 seconds, API requests per 100 seconds. can set API manager Google Cloud Project.Consider additionally Translation API demonstrate review, Google provides us two APIs translation: AutoML Translation Advanced Translation API (see short comparison).","code":""},{"path":"google-translation-api.html","id":"prerequesites-1","chapter":"3 Google Translation API","heading":"3.2 Prerequesites","text":"prerequisites access API (authentication)? access use API following steps necessary:Create google account (already one).Create google account (already one).Using google account login google cloud platform create Google Cloud Project.Using google account login google cloud platform create Google Cloud Project.Within Google Cloud Project enable Google Translation API.Within Google Cloud Project enable Google Translation API.authentication need create API key (additionally restrict Translation API). however, planning request Natural Language API outside Google Cloud environment (e.g., R) required use private (service account) key. can achieved creating service account turn allow download private key JSON file (show example ).authentication need create API key (additionally restrict Translation API). however, planning request Natural Language API outside Google Cloud environment (e.g., R) required use private (service account) key. can achieved creating service account turn allow download private key JSON file (show example ).","code":""},{"path":"google-translation-api.html","id":"simple-api-call-1","chapter":"3 Google Translation API","heading":"3.3 Simple API call","text":"simple API call look like?describe simple API call can made within Google Cloud Platform environment via Google Cloud Shell:activate Cloud Shell, inspect upper right-hand corner Google Cloud Platform Console click icon called “Activate Shell”. Google Cloud Shell command line environment running cloud.activate Cloud Shell, inspect upper right-hand corner Google Cloud Platform Console click icon called “Activate Shell”. Google Cloud Shell command line environment running cloud.Via built-Editor Cloud Shell create JSON file (call instance ‘request.json’) text like perform analysis . Consider text can uploaded request (shown ) integrated Cloud Storage. Supported types text PLAIN_TEXT (shown ) HTML.Via built-Editor Cloud Shell create JSON file (call instance ‘request.json’) text like perform analysis . Consider text can uploaded request (shown ) integrated Cloud Storage. Supported types text PLAIN_TEXT (shown ) HTML.sending data, pass curl command Cloud Shell command line refer (via @) request.json file previous step.sending data, pass curl command Cloud Shell command line refer (via @) request.json file previous step.Don’t forget insert individual API key curl command (alternatively, define beforehand via adding global variable environment → see example API call Googles’ NLP API earlier document).Don’t forget insert individual API key curl command (alternatively, define beforehand via adding global variable environment → see example API call Googles’ NLP API earlier document).","code":"{\n \"q\": [\"To administer medicine to animals is frequently a very difficult matter, and yet sometimes it’s necessary to do so\"], \n\"target\": \"de\"\n}curl \"https://translation.googleapis.com/language/translate/v2?key=APIKEY\" -s -X POST -H \"Content-Type: application/json\" --data-binary @request.json"},{"path":"google-translation-api.html","id":"api-access-1","chapter":"3 Google Translation API","heading":"3.4 API access","text":"can access API R (httr + packages)?following example makes use ‘googleLanguageR’ package R among options (e.g., syntax analysis → see Chapter 2 review) allows calling Cloud Translation API.small example demonstrate …… authenticate Google Cloud Account within R… authenticate Google Cloud Account within R… translate exemplary sentence… translate exemplary sentenceStep 1: Load packageStep 2: AuthenticationStep 3: Analysis - API call TranslationFirst, create exemplary data. demonstration purposes, make use sentence . course, project use complete vector containing text data within data.Next, using data, call API via function ‘gl_translate()’ importantly specify target language (german example) within ‘target’ argument.API call eventually provides reuslts dataframe three columns: translatedText ( → contains translation), detectedSourceLangauge ( → contains label original language detected) text ( → contains original text).Let’s check translation.Tieren Medikamente zu verabreichen ist oft eine sehr schwierige Angelegenheit, und doch ist es manchmal notwendig","code":"\nlibrary(googleLanguageR)\ngl_auth(\"./your-key.json\")\ndf_original <- data.frame(text = \"To administer medicine to animals is frequently a very difficult matter, and yet sometimes it’s necessary to do so\")\n\ndf_original$text <- as.character(df_original$text)\ndf_translate <- gl_translate(df_original$text, target = \"de\")\ndf_translate$translatedText"},{"path":"google-translation-api.html","id":"social-science-examples-1","chapter":"3 Google Translation API","heading":"3.5 Social science examples","text":"social science research examples using API?Searching literature using Google Translation Services found study @Prates2018-fx (Assessing gender bias machine translation: case study Google Translate).aware research / publications made explicit usage Google’s Translation API. However, assume API (least Google’s Free Translation Service) involved many research projects. Generally, convinced making use automated translation (well converting speech text ( → example also review) eventually combination translation) can great advantage kinds qualitative mixed-methods research projects. instance, automated translation useful easily reliably translating data qualitative interviews (field) experiments observational data (data might collected foreign language). Also consider way around data available principal language research project textual data communicated presented (instance) english language.","code":""},{"path":"crowdtangle-api.html","id":"crowdtangle-api","chapter":"4 CrowdTangle API","heading":"4 CrowdTangle API","text":"Lion Behrens Pirmin StöckleCrowdTangle public insights tool, whose main intent monitor content overperformed terms interactions (likes, shares, etc.) Facebook social media platforms. 2016, CrowdTangle acquired Facebook now provides service.","code":""},{"path":"crowdtangle-api.html","id":"provided-servicesdata-2","chapter":"4 CrowdTangle API","heading":"4.1 Provided services/data","text":"data/service provided API?CrowdTangle allows users systematically follow analyze happening public content social media platforms Facebook, Twitter, Instagram Reddit.\ndata can assessed CrowdTangle API consists post made public page, group verified public person ever acquired 110,000 likes since year 2014 ever added list tracked public accounts active API user. new public page group added, data pulled back day one.Data tracked:Content (content post, including text, included links, links included images videos)Interactions (count likes, shares, comments, emoji-reactions)Page FollowersFacebook Video ViewsBenchmark scores metrics middle 50% posts category (text, video) respective accountData tracked:Comments (number comments included, content comments )Demographical dataPage reach, traffic clicksPrivate posts profilesAds appear ad library (public), boosted content differentiated organic contentCrowdTangle’s database updated every fifteen minutes comes time-series data merges content post one included platforms (text post, video, image) alongside aggregate information post’s views, likes interactions.connecting user interface via CrowdTangle website, user can either manually set list pages interest whose data acquired. Alternatively, one can choose extensive number pre-prepared lists covering variety topics, regions, socially politically relevant events inaugurations elections. Data can downloaded user interface csv files json files via API.","code":""},{"path":"crowdtangle-api.html","id":"prerequesites-2","chapter":"4 CrowdTangle API","heading":"4.2 Prerequesites","text":"prerequisites access API (authentication)? Full access CrowdTangle API given Facebook partners business publishing original content fact-checkers part Facebook’s Third-Party Fact-Checking program.\n2019, CrowdTangle API user interface also available academics researchers specific fields. Currently, prioritization includes research one following fields: misinformation, elections, COVID-19 racial justice, well-. get access CrowdTangle, formal request filed via online form, asking short description research project intended use data.restriction, CrowdTangle currently allows academic staff, faculty registered PhD students permission obtain CrowdTangle account. include individuals enrolled students university unless employed research assistants. Also, certain access policies differ academics private sector. Usage CrowdTangle research purposes currently provide access content posted Reddit given data retrieved via Application Programming Interface. Content Reddit open every registered user navigating company’s dynamic user interface imply usage scripting language.\nFinally, CrowdTangle API requires researchers log using existing Facebook account.\nOverall, access API quite restrictive, prioritization certain research areas, access request decided individually immediate access possible. access granted, CrowdTangle provides quite extensive onboarding training resources use API.ReplicabilityAccess CrowdTangle gated Facebook allow data CrowdTangle published. researchers can publish aggregate results analyses data, original data, might problematic replicability research conducted API. possible workaround can pull ID numbers posts dataset, can used anyone CrowdTangle API access recreate dataset.\nCrowdTangle also provides publicly available features Link Checker Chrome Extension, allowing users see often specific link shared social media, curated public hub Live displays, giving insight specific topics Facebook, Instagram Reddit.","code":""},{"path":"crowdtangle-api.html","id":"simple-api-call-2","chapter":"4 CrowdTangle API","heading":"4.3 Simple API call","text":"simple API call look like?requests CrowdTangle API made via GET https://api.crowdtangle.com/.order access data, users log website Facebook account acquire personalized token. CrowdTangle API expects API token included query.\none available endpoints, comes set specific parameters:simple example: party parties posted 10 successful Facebook posts year?user interface, created list pages parties currently German Bundestag. want find party parties posted 10 successful posts (.e. posts interactions) year.respective API call looks like :\nhttps://api.crowdtangle.com/posts?token=token&listIds=listIDs&sortBy=total_interactions&startDate=2021-01-01&count=10, token personal API key, listIDs ID list created user interface. , sortBy total interactions startDate beginning year output restricted count 10 posts.","code":""},{"path":"crowdtangle-api.html","id":"api-access-2","chapter":"4 CrowdTangle API","heading":"4.4 API access","text":"can access API R (httr + packages)?Instead typing API request browser, can use httr package’s GET function access API R.Alternatively, can use wrapper function R, provided RCrowdTangle package available github. package provides wrapper functions /posts, /posts/search, /links endpoints. Conveniently, wrapper function directly produces dataframe output, typically want work . example shows, wrapper function may include specific information looking , however, example also shows, relatively straightforward adapt function depending specific question hand.\ndownload package github, need load devtools package, use wrapper function, need dplyr jsonlite.","code":"\n# Option 1: Accessing the API with base \"httr\" commands\nlibrary(httr)\n \nct_posts_resp <- GET(\"https://api.crowdtangle.com/posts\",\n    query=list(token = token, # API key has to be included in every query\n               listIds = listIds, # ID of the created list of pages or groups\n               sortBy = \"total_interactions\",\n               startDate = \"2021-01-01\",\n               count = 10))\n \nct_posts_list <- content(ct_posts_resp)\nclass(ct_posts_list) # verify that the output is a list\n \n# List content\nstr(ct_posts_list, max.level = 3) # show structure & limit levels\n \n# with some list operations we can get a dataframe with the account name and post date of the 10 posts with the most interactions in 2021 among the pages in the list\nlist_part <- rlist::list.select(ct_posts_list$result$posts, account$name, date)\nrlist::list.stack(list_part)\n# Option 2: There is a wrapper function for R, which can be downloaded from github\n\nlibrary(devtools) # to download from github\n \ninstall_github(\"cbpuschmann/RCrowdTangle\")\nlibrary(RCrowdTangle)\n \n# The R wrapper relies on jsonlite and dplyr\nlibrary(dplyr)\nlibrary(jsonlite)\n \nct_posts_df <- ct_get_posts(listIds, startDate = \"2021-01-01\", token = token)\n \n#conveniently, the wrapper function directly produces a dataframe\nclass(ct_posts_df)\n \n# to sort by total interactions we have to compute that figure because it is not part of the dataframe\nct_posts_df %>%\n  mutate(total_interactions = statistics.actual.likeCount+statistics.actual.shareCount+ statistics.actual.commentCount+  statistics.actual.loveCount+ statistics.actual.wowCount+ statistics.actual.hahaCount+ statistics.actual.sadCount+\n           statistics.actual.angryCount+ statistics.actual.thankfulCount+ statistics.actual.careCount) %>%\n  arrange(desc(total_interactions)) %>%\n  select(account.name, date) %>%\n  head(n=10)\n \n# alternatively, we can adapt the wrapper function by ourselves to include the option to sort by total interactions\nct_get_posts <- function(x = \"\", searchTerm = \"\", language = \"\", types= \"\", minInteractions = 0, sortBy = \"\", count = 100, startDate = \"\", endDate = \"\", token = \"\")\n{\n  endpoint.posts <- \"https://api.crowdtangle.com/posts\"\n  query.string <- paste0(endpoint.posts, \"?listIds=\", x, \"&searchTerm=\", searchTerm, \"&language=\", language, \"&types=\", types, \"&minInteractions=\", minInteractions, \"&sortBy=\", sortBy, \"&count=\", count, \"&startDate=\", startDate, \"&endDate=\", endDate, \"&token=\", token)\n  response.json <- try(fromJSON(query.string), silent = TRUE)\n  status <- response.json$status\n  nextpage <- response.json$result$pagination$nextPage\n  posts <- response.json$result$posts %>% select(-expandedLinks, -media) %>% flatten()\n  return(posts)\n}\n \nct_posts_df <- ct_get_posts(listIds, sortBy = \"total_interactions\", startDate = \"2021-01-01\", token = token)\n \nct_posts_df %>%\n  select(account.name, date) %>%\n  head(n=10)"},{"path":"crowdtangle-api.html","id":"social-science-examples-2","chapter":"4 CrowdTangle API","heading":"4.5 Social science examples","text":"social science research examples using API?common use case track spread specific links containing misinformation, e.g. conspiracy around connection COVID-19 5G (@Bruns2020-pl).\n@Berriche2020-dt provide -depth analysis specific page involved online health misinformation investigate factors driving interactions respective posts. find users mainly interact foster social relations, spread misinformation.\nCrowdTangle also used study changes framing vaccine refusal analyzing content posts pages opposing vaccinations time (@Broniatowski2020-rh).\nAnother approach monitor political communication political actors, specifically run-elections. @Larsson2020-iu investigates one-month period 2018 Swedish election finds right-wing political actors successful mainstream actors engaging Facebook followers, often using sensational rhetoric hate-mongering.","code":""},{"path":"google-places-api.html","id":"google-places-api","chapter":"5 Google Places API","heading":"5 Google Places API","text":"Lukas Isermann Clara Husson","code":""},{"path":"google-places-api.html","id":"provided-servicesdata-3","chapter":"5 Google Places API","heading":"5.1 Provided services/data","text":"data/service provided API?following five requests available: Place Search, Place Details, Place Photos, Place Autocomplete Query Autocomplete. Place Search returns list places along summary information place based user’s location (proximity) search string. find place_id Place Search, can request details particular place Place Details request. Place Details request returns detailed information indicated place complete address, phone number, user rating reviews. Place Photos provides access millions place-related photos stored Google’s Place database. get place information using Place Details request, photo references returned relevant photographic content. Find Place, Nearby Search, Text Search requests also return single photo reference per place, relevant. Place Autocomplete automatically fills name /address place users type. Query Autocomplete service provides query prediction text-based geographic searches, returning suggested queries type.Note: can display Places API results Google Map, without map prohibited use Places API data map Google map.","code":""},{"path":"google-places-api.html","id":"prerequesites-3","chapter":"5 Google Places API","heading":"5.2 Prerequesites","text":"prerequisites access API (authentication)? prerequisites access Google Places API Google Cloud project (create need Google account log Google Cloud Platform) API Key. creating API Key, don’t forget enable Places API! create API key, go APIs & Services > Credentials > API key page.","code":""},{"path":"google-places-api.html","id":"simple-api-call-3","chapter":"5 Google Places API","heading":"5.3 Simple API call","text":"simple API call look like?API provides different searches services can accessed via HTTP Urls. Urls requests take general form pattern:https://maps.googleapis.com/maps/api/place/service/output?parametersHere, service can take inputs findplacefromtext find place requests, nearbysearch look nearby places, details request place details . output may take value json xml, dependent requested output format.Furthermore, certain parameters required requests. importantly, every request must entail key parameter, indicating API key. Second, search places requests take input parameter identifies search target inputtype parameter identifies type input given input parameter. place requests, inputtype parameter can take values textquery phonenumber.Nearby requests take location parameter setting longitude latitude requested place well radius parameter. Detail request, however, take mandatory parameter place_id, indicates place details requested.Additionally, different optional parameters can used. entail language parameter, fields parameter indicating types place data return .examples API request pizza places Mannheim can look like :https://maps.googleapis.com/maps/api/place/textsearch/xml?query=pizza&location=49.487459,8.466039&radius=5000&key=YOUR_API_KEY","code":""},{"path":"google-places-api.html","id":"api-access-3","chapter":"5 Google Places API","heading":"5.4 API access","text":"can access API R (httr + packages)?Instead typing API request browser, can use httr package’s GET function access API R.Alternatively, can use wrapper function R provided R-Package googleway.AuthenticationAPI call","code":"\n# Option 1: Accessing the API with base \"httr\" commands\nlibrary(httr)\n\nkey <- \"YOURAPIKEY\"\n\nres<-GET(\"https://maps.googleapis.com/maps/api/place/textsearch/json?\", query = list(\n           query = \"pizza\",\n           location = \"49.487459,8.466039\",\n           radius = 5000,\n           key = key\n         ))\nkey <- \"YOURAPIKEY\"\nset_key(key)\n# Option 2: Accessing the API with googleway\n\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(googleway)\n\n# Request 'Mannheim' to get latitude and longitude information\nlocation <- googleway::google_places(\"Mannheim\")\n\n\n# Save latitude and longitude information in vector\nlocation <- location$results$geometry\nlocation <- c(location$location$lat, location$location$lng)\n\n\n# Plot places to google map\nlibrary(mapsapi)\n# for this you will also need to activate the \"maps static API\"\nr = mapsapi::mp_map(center = (\"49.48746,8.466039\"), zoom = 14, key = key, quiet = TRUE)\nlibrary(stars)\nplot(r)\n# Google places request with googleway\npizza <- google_places(\"Pizza\", location = location, radius = 5000, place_type = \"food\")\n\n# Plot rankings as barplot\npizza$results %>%\n  ggplot() +\n  geom_col(aes(x = reorder(name, rating), y = rating)) +\n  geom_text(aes(x = reorder(name, rating), y = rating),\n                label = paste0(pizza$results$user_ratings_total, \" \\n ratings\"), size = 2) +\n  ylab(\"Average Rating\")+\n  xlab(\"\") +\n  ggtitle(\"Pizza Places in Mannheim by Rating\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, size = 8, hjust=0.95,vjust=0.2))\n# Plot pizza places to google map\n#important: in order to display the map correctly, you will also have to enable the Maps JavaScript API on GCP\n# unfortunately we can not display an intercative card in this document, but check out the below code in your own rmd-file! \n\nmap<-googleway::google_map(location = location)\ngoogleway::add_markers(map, data = pizza$results$geometry$location)"},{"path":"google-places-api.html","id":"social-science-examples-3","chapter":"5 Google Places API","heading":"5.5 Social science examples","text":"social science research examples using API?study “Using Google places data analyze changes mobility COVID-19 pandemic”, @Konrad2020-rl looked “popular times” data provided Google Places measure effect social distancing effort mobility.","code":""},{"path":"google-speech-to-text-api.html","id":"google-speech-to-text-api","chapter":"6 Google Speech-to-Text API","heading":"6 Google Speech-to-Text API","text":"Camille Landesvatter","code":""},{"path":"google-speech-to-text-api.html","id":"provided-servicesdata-4","chapter":"6 Google Speech-to-Text API","heading":"6.1 Provided services/data","text":"data/service provided API?Google’s Speech--Text API allows convert audio files text applying powerful neural network models. Audio content can transcribed real time course (possibly higher relevance social science research) stored files.API currently recognizes 125 languages. supports multiple audio formats, audio files can either transcribed directly (content exceed 60 seconds) perform asynchronous requests audio files longer 60 seconds.demo API allows record text via microphone (upload audio file) explore transcript can found .Also consider Text--Speech API - simply performing operations way around - offered Google.","code":""},{"path":"google-speech-to-text-api.html","id":"prerequesites-4","chapter":"6 Google Speech-to-Text API","heading":"6.2 Prerequesites","text":"prerequisites access API (authentication)? access use API following steps necessary:Create google account (already one).Create google account (already one).google account login google cloud platform create Google Cloud Project.google account login google cloud platform create Google Cloud Project.Within Google Cloud Project enable Google Speech--text API.Within Google Cloud Project enable Google Speech--text API.authentication need create API key (additionally restrict Translation API). however, planning request Natural Language API outside Google Cloud environment (e.g., R) required use private (service account) key. can achieved creating service account turn allow download private key JSON file (show example ).authentication need create API key (additionally restrict Translation API). however, planning request Natural Language API outside Google Cloud environment (e.g., R) required use private (service account) key. can achieved creating service account turn allow download private key JSON file (show example ).","code":""},{"path":"google-speech-to-text-api.html","id":"simple-api-call-4","chapter":"6 Google Speech-to-Text API","heading":"6.3 Simple API call","text":"simple API call look like?Note. Google’s Translation API well Google’s Natural-Language API, review demonstrate example simple API call via Google Cloud Shell. principle (similar procedure) can achieved Speech--Text API. However, audio file need pre-processing. Audio data (exemplary file wav-format) binary data. make REST request (via Google Cloud Shell) however JSON used. JSON eventually support binary data transform binary audio file text using Base64 encoding (also refer documentation Google Website information). enter audio data Base64 encoded, Google Cloud Shell give error 400 stating Base64 decoding failed (wav-)file. Nevertheless, box provide basic structure request.activate Cloud Shell, inspect upper right-hand corner Google Cloud Platform Console click icon called “Activate Shell”. Google Cloud Shell command line environment running cloud.activate Cloud Shell, inspect upper right-hand corner Google Cloud Platform Console click icon called “Activate Shell”. Google Cloud Shell command line environment running cloud.Via built-Editor Cloud Shell create JSON file (call instance ‘request.json’). can either upload audio file directly via Google Cloud Shell (search three-dotted “” menu Shell select “Upload file”), alternatively audio content can integrated Cloud Storage.Via built-Editor Cloud Shell create JSON file (call instance ‘request.json’). can either upload audio file directly via Google Cloud Shell (search three-dotted “” menu Shell select “Upload file”), alternatively audio content can integrated Cloud Storage.wav.file uploaded example exemplary wav.file comes along ‘googleLanguageR’ R package.wav.file uploaded example exemplary wav.file comes along ‘googleLanguageR’ R package.sending data, pass curl command Cloud Shell command line refer (via @) request.json file previous step.sending data, pass curl command Cloud Shell command line refer (via @) request.json file previous step.Don’t forget insert individual API key (alternatively, define beforehand via variable environment -> see example API call Google’s NLP API later document).Don’t forget insert individual API key (alternatively, define beforehand via variable environment -> see example API call Google’s NLP API later document).","code":"{\n  \"audio\": {\n    \"content\": \"woman1_wb\"\n  },\n  \"config\": {\n    \"enableAutomaticPunctuation\": true,\n    \"encoding\": \"LINEAR16\",\n    \"languageCode\": \"en-US\",\n    \"model\": \"default\"\n  }\n}curl \"https://speech.googleapis.com/v1p1beta1/speech:recognize?key=APIKEY\" -s -X POST -H \"Content-Type: application/json\" --data-binary @request.json"},{"path":"google-speech-to-text-api.html","id":"api-access-4","chapter":"6 Google Speech-to-Text API","heading":"6.4 API access","text":"can access API R (httr + packages)?Example using R-Package ‘googleLanguageR’small example demonstrate ..*.. authenticate Google Cloud Account within R*.. import exemplary audiofile “GoogleLanguageR” package*.. transcribe audio file calculate confidence scoreFor usage arguments, also read gl_speech() documentation vignette.1. Load packagesStep 2: AuthenticationStep 3: AnalysisWe now get sample source file comes along googleLanuageR package. transcript file : “administer medicine animals frequently difficult matter, yet sometimes ’s necessary ” - according @Edmondson2017-pv (one authors ‘googleLanguageR’ R package) fairly difficult sentence computers parse.can now call API via function gl_speech(). specify quantity interest, namely audio_source (can either local file Google Cloud Storage URI) well languageCode (language spoken audio file).result list containing two dataframes: transcript timings.timings dataframe stores timestamps telling us specific term recognised. transcript dataframe importantly provides transcript well confidence score. can see transcript misses one term (“”) indicates confidence score close 1.0.administer medicine animals frequently difficult matter yet sometimes ’s necessary ","code":"\nlibrary(tidyverse)\nlibrary(googleLanguageR)\ngl_auth(\"./your-key.json\")\ntest_audio <- system.file(\"woman1_wb.wav\", package = \"googleLanguageR\")\naudio_data <- gl_speech(audio_source=test_audio, languageCode = \"en-GB\")\ndimnames(audio_data$transcript)## [[1]]\n## [1] \"1\"\n## \n## [[2]]\n## [1] \"transcript\"   \"confidence\"   \"languageCode\" \"channelTag\"\naudio_data$transcript$transcript\naudio_data$transcript$confidence #0.92## [1] \"0.9151854\""},{"path":"google-speech-to-text-api.html","id":"social-science-examples-4","chapter":"6 Google Speech-to-Text API","heading":"6.5 Social science examples","text":"social science research examples using API?Similar note social science research examples Google’s Translation API, aware research made explicit usage Google’s Speech--text API.\nHowever, especially combination Translation API, convinced speech--text conversion can great advantage kinds qualitative mixed-methods research projects.","code":""},{"path":"instagram-graph-api.html","id":"instagram-graph-api","chapter":"7 Instagram Graph API","heading":"7 Instagram Graph API","text":"Philipp Kadel","code":""},{"path":"instagram-graph-api.html","id":"provided-servicesdata-5","chapter":"7 Instagram Graph API","heading":"7.1 Provided services/data","text":"data/service provided API?Instagram Graph API provided Facebook. two main APIs Instagram, Instagram Basic Display API Instagram Graph API. latter described following.API can used get manage published photos, videos, stories well getting basic data Instagram Business users Creators. also possible moderate comments replies measure media profile interaction. Photos videos can published directly API. can also used discover hashtagged media mentions.photos videos different metrics can obtained:engagement – Total number likes comments media object.Impressions – Total number times media object seen.Reach – Total number unique accounts seen media object.Saved – Total number unique accounts saved media object.Video_views – (Videos ) Total number times video seen. Returns 0 videos carousel albums.Likewise, several metrics stories provided API:Exits – Number times someone exited story.Impressions – Total number times story seen.Reach – Total number unique accounts seen story.Replies – Total number replies story.Taps_forward – Total number taps see story’s next photo video.","code":""},{"path":"instagram-graph-api.html","id":"prerequesites-5","chapter":"7 Instagram Graph API","heading":"7.2 Prerequesites","text":"prerequisites access API (authentication)? endpoints need Instagram Business Account, Facebook Page connected account, Facebook Developer Account Facebook App Basic settings configured. Facebook provides tutorial setting .","code":""},{"path":"instagram-graph-api.html","id":"simple-api-call-5","chapter":"7 Instagram Graph API","heading":"7.3 Simple API call","text":"simple API call look like?can find expamples simple API calls Instagram Graph API.Get Fields Edges IG Media. Fields can e.g., “caption”, “comments_count”, “like_count”, “timestamp”.GET (“https://graph.facebook.com/v10.0/{ig-media-id} ?fields={fields} &access_token={access-token}”)Example:Response:Return Fields Edges IG Hashtag. Field can name hashtag without “#” symbol hashtag ID.GET (“https://graph.instagram.com/{ig-hashtag-id}\n?fields={fields}\n&access_token={access-token}”)Example:Response:Get fields edges Instagram Business Creator Account. Fields can e.g., “biography”, “id”, “followers_count”, “media_count”.GET (“https://graph.facebook.com/v10.0/{ig-user-id}?fields={fields} &access_token={access-token}”)Example:Response:","code":"GET (“https://graph.facebook.com/v10.0/17895695668004550\n      ?fields=id,media_type,media_url,owner,\n      timestamp&access_token=IGQVJ...”){\n  \"id\": \"17895695668004550\",\n  \"media_type\": \"IMAGE\",\n  \"media_url\": \"https://fb-s-b-a.akamaihd.net/h-ak-fbx/t51.2885-9/21227247_1640962412602631_3222510491855224832_n.jpg?_nc_log=1\",\n  \"owner\": {\n    \"id\": \"17841405822304914\"\n  },\n  \"timestamp\": \"2017-08-31T18:10:00+0000\"GET (“https://graph.facebook.com/17841593698074073\n?fields=id,name\n&access_token=EAADd...”){ \"id\": \"17841593698074073\",\n  \"name\": \"coke\" }GET (“https://graph.facebook.com/v3.2/17841405822304914\n      ?fields=biography%2Cid%2Cusername%2Cwebsite&access_token=EAACwX...”){  \"biography\": \"Dino data crunching app\",\n  \"id\": \"17841405822304914\",\n  \"username\": \"metricsaurus\",\n  \"website\": \"http://www.metricsaurus.com/\" }"},{"path":"instagram-graph-api.html","id":"api-access-5","chapter":"7 Instagram Graph API","heading":"7.4 API access","text":"can access API R (httr + packages)?httr package can used access Instagram Graph API. used instaR package made old Instagram API can used anymore. FBinsightsR package provides access Insights API. fbins_insta function can used collect Instagram insights. Detailed information packages’ functions can found information deprecated instaR package .","code":""},{"path":"instagram-graph-api.html","id":"social-science-examples-5","chapter":"7 Instagram Graph API","heading":"7.5 Social science examples","text":"social science research examples using API?study, @Ferwerda2015-db tried infer personality traits way users take pictures apply filters . authors found distinct picture features (e.g., hue, brightness, saturation) related personality traits. @Brown2019-jp investigated link acute suicidality language use well activity Instagram. Differences activity language use Instagram associated acute suicidality. goal study @Hosseinmardi2015-yc automatically detect predict incidents cyberbullying Instagram. Based sample data set consisting Instagram images associated comments, media sessions labeled cyberbullying. Associations investigated cyberbullying host features cyber aggression, profanity, social graph features, temporal commenting behavior, linguistic content, image content.","code":""},{"path":"instagram-basic-display-api.html","id":"instagram-basic-display-api","chapter":"8 Instagram Basic Display API","heading":"8 Instagram Basic Display API","text":"Madleen Meier-BartholdInitially released 2010, Instagram currently counts 1+ billion monthly active users 50+ billion photos stored (@Tankovska_undated-ph). User engagement high, average 28 minutes per day spent platform 2020 (@Aslam2021-fp). Needless say, photo video sharing social networking service holds invaluable data leveraged social researchers.","code":""},{"path":"instagram-basic-display-api.html","id":"provided-servicesdata-6","chapter":"8 Instagram Basic Display API","heading":"8.1 Provided services/data","text":"data/service provided API?Instagram offers two types APIs allow application access data platform: Instagram Graph API Instagram Basic Display API.Previously, APIs available allowed developers researchers less restricted access data collection (@Instagram2021-ii). older APIs now depreciated.Instagram Basic Display API gives read-access basic profile information, photos videos authenticated users’ accounts (@Facebook_for_Developers2021-mn). Particularly, possible fetch user’s profile, including fields like account type account name, well user’s media (images, videos albums), including fields like media type, caption, URL timestamp. API allow modify data like publishing media moderating comments (see Instagram Graph API).RESTful API, meaning queries made static information current moment. Queries subject rate limits. Responses form JSON-formatted objects containing default requested fields edges.","code":""},{"path":"instagram-basic-display-api.html","id":"prerequesites-6","chapter":"8 Instagram Basic Display API","heading":"8.2 Prerequesites","text":"prerequisites access API (authentication)? order access Instagram Basic Display API, developers required first register Facebook developer developers.facebook.com, create Facebook App submit application review.Another prerequisite access API get authentication. API authentication handled Instagram User Access Tokens conform OAuth 2.0 protocol. process getting access token includes two parts. First, application user must grant application permission read user node /media node. permissions controlled via Authorization Window.Give URL application users. next steps completed user.Open new browser window load Authorization Window URL.Open new browser window load Authorization Window URL.Authenticate Instagram test user signing Authorization WindowAuthenticate Instagram test user signing Authorization WindowClick Authorize grant app access profile data.Click Authorize grant app access profile data.Upon success, page redirect redirect URI included previous step append Authorization Code. example: https://mmeierba.github.io/?code=AQD…#_Upon success, page redirect redirect URI included previous step append Authorization Code. example: https://mmeierba.github.io/?code=AQD…#_Copy code except #_ portion end. Send Authorization Code researcher.Copy code except #_ portion end. Send Authorization Code researcher.user successfully grants application permission access data, user redirected redirect URI appended Authorization Code. Second, Authorization Code can exchanged short-lived access token (.e., valid 1 hour)., API can queried.","code":"https://api.instagram.com/oauth/authorize\n  ?client_id={appId}\n  &redirect_uri={redirectURI}\n  &scope=user_profile,user_media\n  &response_type=code\nlibrary(httr)\n\nappId = \"126...\" #use Instagram App ID and secret (not Facebook App)\nappSecret = \"b73...\" \nredirectUri = \"https://mmeierba.github.io/\" #example\ncode = \"AQD...\"\n\nid<-POST(\"https://api.instagram.com/oauth/access_token\", \n     body=list(client_id=appId, client_secret=appSecret, grant_type=\"authorization_code\", redirect_uri=redirectUri, code=code))"},{"path":"instagram-basic-display-api.html","id":"simple-api-call-6","chapter":"8 Instagram Basic Display API","heading":"8.3 Simple API call","text":"simple API call look like?Instagram Basic Display API http-based. query node edge, GET call can used. base URLs api.instagram.com graph.instagram.com.","code":"\naccessToken = \"...\"\nuserId = \"...\"\n\n## Query the user node\nGET(\"https://graph.instagram.com/userId?fields=id,username&access_token=accessToken\") \nGET(\"https://graph.instagram.com/me?fields=id,username&access_token=accessToken\") #alternative\n\n\n## Query the user media edge\nGET(\"https://graph.instagram.com/me/media?fields=id,caption&access_token=accessToken\")\n\n## Query the user media node\nmediaId = \"...\"\n\nGET(\"https://graph.instagram.com/mediaId?fields=id,media_type,media_url,username,timestamp&access_token=accessToken\")"},{"path":"instagram-basic-display-api.html","id":"api-access-6","chapter":"8 Instagram Basic Display API","heading":"8.4 API access","text":"can access API R (httr + packages)?Instagram Graphic Display API can accessed R using httr package.Current R packages specific APIs Instagram (e.g., instaR) related deprecated versions Instagram APIs therefore longer useful current version (@Instagram2021-ii). knowledge authors, R packages specific Instagram Basic Display API.social science research examples using API?couple examples studies field social science used Instagram API. However, presented examples use older, depreciated versions Instagram API.@Hu2014-br collected 50 user profiles recent photos, well users’ lists friends followers using Instagram API. Analyzing data, authors identified range photo categories types Instagram users.@Ferwerda2015-db used Instagram API extract Instagram pictures survey participants, previously filled personality questionnaire. 113 survey participants granted researchers access Instagram accounts API. authors found distinct features Instagram pictures (.e., hue, brightness, saturation) associated users’ personality traits.examples show potential extracting data using Instagram Basic Display API social science researchers. Yet, lot data yet leveraged (e.g., captions).","code":""},{"path":"googletrends-api.html","id":"googletrends-api","chapter":"9 GoogleTrends API","heading":"9 GoogleTrends API","text":"Jan Behnert, Dean Lajic","code":""},{"path":"googletrends-api.html","id":"provided-servicesdata-7","chapter":"9 GoogleTrends API","heading":"9.1 Provided services/data","text":"data/service provided API?API provided Google.Google Trends, one gets access largely unfiltered sample actual search topics (36h search) filtered representative sample search topics older 36 hours starting year 2004. data anonymized, can obtained different Google products like “Web search”, “News”, “Images”, “Shopping” “Youtube,” can filtered different categories get data correct meaning word, aggregated, means searches cities/regions aggregated federal state level, country level world level. results get standardized measure search volume single search terms, combination search terms using operators (see table ), comparisons (one input relation inputs) selected time period. Google calculates much search volume region search term query , relative searches region. Using information, Google assigns measure popularity search terms (scale 0 - 100), leaving repeated searches person short period time searches apostrophes special characters.","code":""},{"path":"googletrends-api.html","id":"prerequesites-7","chapter":"9 GoogleTrends API","heading":"9.2 Prerequesites","text":"prerequisites access API (authentication)? can used without API key anyone free directly internet browser (sign needed).","code":""},{"path":"googletrends-api.html","id":"simple-api-call-7","chapter":"9 GoogleTrends API","heading":"9.3 Simple API call","text":"simple API call look like?Just click .","code":""},{"path":"googletrends-api.html","id":"api-access-7","chapter":"9 GoogleTrends API","heading":"9.4 API access","text":"can access API R (httr + packages)?Example using “httr” package:just html-output, recommend use gtrendsR package\nExample using “gtrendsR” package:Note (1): use c() keyword argument gtrends function allows comparisons 5 searches (separator = comma).Note (2): use pattern ‘“xyz”’ keyword argument gtrends function corresponds inverted commas table , punctuation methods table can used indicated table.","code":"\nlibrary(httr)\nGET(\"https://trends.google.com/trends/explore\",\n    query=list(q = \"Covid\",geo = \"US\"))\n# visualizing google searches for the word \"corona symptoms\" in \n# Germany and Austria in the period 01/01/2020 - 27/04/2021\nlibrary(gtrendsR)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(\"countries\") # get abbreviations of all countries to filter data \ndata(\"categories\") # get numbers of all categories to filter data \n\n# Simple call\n\nres <- gtrends(\"corona symptome\",geo=c(\"DE\", \"AT\"))\nplot(res)\n#Combination using dplyr and ggplot\ntrend = gtrends(keyword=\"corona symptome\", geo=c(\"DE\", \"AT\"), time = \"2020-01-01 2021-04-27\", gprop=\"web\") \n\ntrend_df <- trend$interest_over_time\n\ntrend_df <- trend_df %>%\n    mutate(hits = as.numeric(hits), date = as.Date(date)) %>%\n    replace(is.na(.), 0)\n\nggplot(trend_df, aes(x=date, y=hits, group=geo, col=geo)) + geom_line(size=2) +\nscale_x_date(date_breaks = \"2 months\" , date_labels = \"%b-%y\") +\nlabs(color= \"Countries\") +\nggtitle(\"Frequencies for the query -corona symptoms- in the period: 01/01/2020 - 27/04/2021\")"},{"path":"googletrends-api.html","id":"social-science-examples-6","chapter":"9 GoogleTrends API","heading":"9.5 Social science examples","text":"social science research examples using API?Google Trends can used predict outcomes elections. example study (@Prado-Roman2021) uses Google Trends data predict past four elections United States past five Canada, since Google first published search statistics 2004. analysed candidate Google searches months leading election day show, help data, actual winners elections held since 2004 predicted.\nAnother example study @Mavragani2019 uses Google Trends data predict results referendums (Scottish referendum 2014, Greek referendum 2015, British referendum 2016, Hungarian referendum 2016, Italian referendum 2016 Turkish referendum 2017). can shown results Google Trends data quite similar actual referendum results cases even accurate official polls. argued help Google Trends data revealed preferences instead users’ stated preferences can analyzed data source helpful source analyze predict human behavior (given areas Internet widely accessible restricted).\nFurthermore, Google Trends data can also utilized fields, example examine whether COVID-19 associated lockdowns initiated Europe America led changes well-related topic search-terms. study @Brodeur2021 finds increase queries addressing boredom, loneliness, worry sadness, decrease search terms like stress, suicide divorce. Indicating people’s mental health strongly affected pandemic lockdowns.","code":""},{"path":"youtube-api.html","id":"youtube-api","chapter":"10 Youtube API","heading":"10 Youtube API","text":"Melike Kaplan, Jana Klein","code":""},{"path":"youtube-api.html","id":"provided-servicesdata-8","chapter":"10 Youtube API","heading":"10.1 Provided services/data","text":"data/service provided API?API provided Google, Youtube’s parent company.different types Youtube APIs serve different purposes:YouTube Analytics API: retrieves YouTube Analytics data.YouTube Data API v3: provides access YouTube data, videos, playlists, channels.YouTube oEmbed API: oEmbed elegant way embed multimedia link.YouTube Reporting API: Schedules reporting jobs containing YouTube Analytics data downloads resulting bulk data reports form CSV files.google developer site provides sample requests summary possible metrics API can give data . can actually run API requests . possible calls can make provided page: Captions, ChannelBanners, Channels, ChannelSection, Comments, CommentThreads, i18nLanguages, i18nRegrions, Members, MembershipLevels, Playlistitems, Playlists, Search, Subscriptions, Thumbnails, VideoAbuseReportReasons, VideoCategories, Videos.","code":""},{"path":"youtube-api.html","id":"prerequesites-8","chapter":"10 Youtube API","heading":"10.2 Prerequesites","text":"prerequisites access API (authentication)? First, need Google account use log Google Cloud Platform. need create new project unless already one (can find information). , can search four Youtube APIs (YouTube Analytics API, YouTube Data API v3, YouTube oEmbed API, YouTube Reporting API) mentioned enable (can find information)., continue “APIs Services” Page sidebar click “Credentials.” Click “+ Create Credentials” top page. three options : API Key, OAuth client ID Service account. API Key identify project simple key check quota access wish use YouTube API app, create OAuth client ID request user consent app can access user’s data. also necessary want use tuber package. Service account enables server server, app-level authentication using robot accounts. continue option creating API Key, later provide example using OAuth Client ID tuber package.click “API Key” “+Create Credentials” list, screen appear like :key created! important restrict key!","code":""},{"path":"youtube-api.html","id":"simple-api-call-8","chapter":"10 Youtube API","heading":"10.3 Simple API call","text":"simple API call look like?base URL https://www.googleapis.com/youtube/v3/.\nfollowing API call tried get channel statistics SWR youtube channel. channel statistics include information viewer count, subscriber count, whether hidden subscribers video count.\nhttps://youtube.googleapis.com/youtube/v3/channels?part=statistics&id=UCy4_zQ59zmS7zO4Dc6vbT_w&key=[Your_API_Key]\nHowever, call work us, got error code 400 said API key valid.","code":""},{"path":"youtube-api.html","id":"api-access-8","chapter":"10 Youtube API","heading":"10.4 API access","text":"can access API R (httr + packages)?Example get channel statistics:CRAN found “tuber” package. package enables get comments posted YouTube videos, number likes video, search videos specific content much . can also scrape captions videos. able use tuber package, API key authentication OAuth necessary. OAuth (Open Authorization) uses authorization tokens prove identity consumers service providers. can get client ID secret Google Cloud Platform Credentials.Setting “Consent Screen”\nFirst configure -called OAuth consent screen, put “external” put app name. scopes specify anything just clicked save & continued. able use API set google mail address use Google cloud.Setting “Consent Screen”\nFirst configure -called OAuth consent screen, put “external” put app name. scopes specify anything just clicked save & continued. able use API set google mail address use Google cloud.Get OAuth credentials\nsetting consent screen can go back click “create credentials” add “OAuth client ID”. result get OAuth client id secret. can download information stored JSON file. Yt_oauth function can authenticate . forward us logging google account. Allow access google account. (like google bigquery).Get OAuth credentials\nsetting consent screen can go back click “create credentials” add “OAuth client ID”. result get OAuth client id secret. can download information stored JSON file. Yt_oauth function can authenticate . forward us logging google account. Allow access google account. (like google bigquery).page provides example API calls can make tuber package.Package information:\n* CRAN - Package tuber\n* can find functions tuber package provides","code":"\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(here)\nlibrary(dplyr)\nlibrary(ggplot2)\n#save your API key in the object key\nkey<-\"Your_API_Key\"\n\n#YouTube channels either have a channel id or a user id\nZDF_Magazin_Royle<-\"UCNNEMxGKV1LsKZRt4vaIbvw\" #channel id\nBoilerroom <- \"brtvofficial\" #user id\n\n#save the base URL in the object base\nbase<- \"https://www.googleapis.com/youtube/v3/\"\n\n#get channel info with channel id\napi_params <- \n  paste(paste0(\"key=\", key), \n        paste0(\"id=\", ZDF_Magazin_Royle), \n        \"part=snippet,contentDetails,statistics\",\n        sep = \"&\")\napi_call <- paste0(base, \"channels\", \"?\", api_params)\napi_result <- GET(api_call)\njson_result <- content(api_result, \"text\", encoding=\"UTF-8\")\n\n#format json into dataframe\nchannel.json <- fromJSON(json_result, flatten = T)\nchannel.df <- as.data.frame(channel.json)\n\n#example with a username\napi_params2 <- \n  paste(paste0(\"key=\", key), \n        paste0(\"forUsername=\", Boilerroom), \n        \"part=snippet,contentDetails,statistics\",\n        sep = \"&\")\napi_call2 <- paste0(base, \"channels\", \"?\", api_params2)\napi_result2 <- GET(api_call2)\njson_result2 <- content(api_result2, \"text\", encoding=\"UTF-8\")\n\n#format json into dataframe\nchannel.json2 <- fromJSON(json_result2, flatten = T)\nchannel.df2 <- as.data.frame(channel.json2)\nlibrary(tuber) # youtube API\nlibrary(magrittr) # Pipes %>%, %T>% and equals(), extract().\nlibrary(tidyverse) # all tidyverse packages\nlibrary(purrr) # package for iterating/extracting data\n#save client id and secret in an object\nclient_id<-\"put client ID\"\nclient_secret<-\"put client secret\"\n\n# use the youtube oauth \nyt_oauth(app_id = client_id,\n         app_secret = client_secret,\n         token = '')\n\n#Downloading playlist data\n#first get playlist ID\ngo_psych_playlist_id <- stringr::str_split(\n  string = \"https://www.youtube.com/playlist?list=PLD4cyJhQaFwWZ838zZhWVr3RG_nETlICM\", \n  pattern = \"=\", \n  n = 2,\n  simplify = TRUE)[ , 2]\ngo_psych_playlist_id\n\n#use the tuber function get_playlist_items to collect the videos into a data frame\n\ngo_psych <- tuber::get_playlist_items(filter = \n                                                c(playlist_id = \"PLD4cyJhQaFwWZ838zZhWVr3RG_nETlICM\"), \n                                              part = \"contentDetails\",\n                                              # set this to the number of videos\n                                              max_results = 200) \n\n# check the data for go Psych\n#now we have the video ids of all videos in that playlist\ngo_psych %>% dplyr::glimpse(78)"},{"path":"youtube-api.html","id":"social-science-examples-7","chapter":"10 Youtube API","heading":"10.5 Social science examples","text":"social science research examples using API?study “Identifying Toxicity Within YouTube Video Comment” (@Obadimu2019), researchers utilized YouTube Data API collect comments eight YouTube channels either pro- anti NATO. comments, five types toxicity scores assigned analyze hateful comments. word clouds researchers able quantify count words comments. final dataset contained 1,424 pro-NATO videos 8,276 comments, 3,461 anti-NATO videos 46,464 comments.aim study “YouTube channels, uploads views: statistical analysis past 10 years” (@Baertl2018) give overview YouTube developed past 10 years terms consumption production videos. study utilizes random sample channel video data answer question. data retrieved YouTube API (specify one) combined tool generated random string searches find near-random sample channels created 01.01.2016 31.12.2016. Results channels, views video uploads differ according video genre. Furthermore, analysis revealed majority views obtained channels. average, older channels larger amount viewers.study “ranking algorithms ‘ranking cultures’: Investigating modulation visibility YouTube search results” (@Rieder2018), YouTube conceptualized influential source information uses socio-algorithmic process order place search recommendations hierarchy. process ranking considered construction relevance knowledge large pool information. Therefore, search function serves curator recommended content. information transmitted content can also impose certain perspectives users algorithm works especially important comes controversial issues. order better understand algorithms determine search rankings YouTube work, authors use scraping approach YouTube API v3 study ranking certain sociocultural issues time. Examples keywords use ‘gamergate,’ ‘trump,’ ‘refugees’ ‘syria.’ find three general types morphologies rank change.","code":""},{"path":"ckan-api.html","id":"ckan-api","chapter":"11 CKAN API","heading":"11 CKAN API","text":"Barbara K. KreisThe CKAN API API offered open-source data management system (DMS) CKAN (Open Knowledge Foundation). Currently, CKAN used DMS many different users, governmental institutions corporations alike.\nAPI review focus use CKAN API access work open government data. CKAN DMS used various governments offer open datasets, helpful tool researchers access treasure publicly open information. CKAN hosts free datasets various governments, Germany, Canada, Australia, Switzerland many .","code":""},{"path":"ckan-api.html","id":"provided-servicesdata-9","chapter":"11 CKAN API","heading":"11.1 Provided services/data","text":"data/service provided API?CKAN’s core features can accessed via CKAN API (Open Knowledge Foundation)\nCKAN API, canGet JSON-formatted list site’s objects, datasets groups.Get full JSON representation object, e.g. dataset.Search packages (datasets) resources match query.Get activity stream recently changed datasets site.Please see following link information services provided CKAN API specific examples.\ncomes specific datasets government sites, two types can accessed: specific datasets meta data sets.\nexample, German US Government website , can get access metadata include descriptions URLs specific open datasets can accessed. meta datasets can starting point research specific topic.\nspecific datasets include variety different contents public administration, election results, data schools, maps many . German data portal govdata.de example serves collection point data various institutions. specific administrative institutions ones actually provide data. Therefore, every institution provides data topic.","code":""},{"path":"ckan-api.html","id":"prerequesites-9","chapter":"11 CKAN API","heading":"11.2 Prerequesites","text":"prerequisites access API (authentication)? prerequisites access CKAN API. Furthermore, seem prerequisites access open data various governmental institutions using CKAN.","code":""},{"path":"ckan-api.html","id":"simple-api-call-9","chapter":"11 CKAN API","heading":"11.3 Simple API call","text":"simple API call look like?user wants make API call, two use cases distinguished: Calling meta-data calling specific datasets.Meta-datasetsWhen calling meta data, DCAT catalog queried. DCAT-AP.de German metadata model exchange open government data. information information meta data structure, see website.\nAPI call DCAT catalog can deliver three formats: RDF, Turtle JSON-LD. type format can specified end request (e.g. “format=jsonld”).\nfollowing API call example search term “Kinder”.\nhttps://ckan.govdata.de/api/3/action/dcat_catalog_search?q=kinder&format=jsonldSpecific datasets GovDataTo look specific datasets, meta data, little changed URL. case querying specific datasets, response format JSON.\nfollowing API call example looking first 5 packages (datasets) contain search term “Kinder” (=children).https://www.govdata.de/ckan/api/3/action/resource_show?q=kinder","code":""},{"path":"ckan-api.html","id":"api-access-9","chapter":"11 CKAN API","heading":"11.4 API access","text":"can access API R (httr + packages)?CKAN API can accessed R httr package ckanr package.\nPlease note scientist can use GET requests. kinds POST requests restricted government employees work institutions provide data sets.","code":"\n# CKAN API #\n# Option 1: Use the httr package to access the API\n\nlibrary(httr) # required to work with the API\n\n# With the following query we get the same information as described in the paragraph above\n\nbase_url <- \"https://www.govdata.de/ckan/api/3/action/resource_show\"\nberlin <- GET(base_url, query=list(q=\"kinder\",rows=5))\n# Option 2: Use the ckanr package to access the API\n\n# load relevant packages\nlibrary(tidyverse)\nlibrary(ckanr)\nlibrary(jsonlite)\nlibrary(readxl)\nlibrary(curl)\nlibrary(readxl)\n\n#connect to the website\nurl_site <- \"https://www.govdata.de/ckan\"\nckanr_setup(url = url_site)\n\n# first, let's see which groups are on this site\ngroup_list(as = \"table\")\n\n\n#you can see there are different groups\n#now we want to look at them in more detail\ngroup_list(limit = 2)\n\n# now you can look for the specific packages\npackage_list(as = \"table\")\n\n# now, let's look at a specific package more closely, to get some more information\npackage_show(\"100-jahre-stadtgrun-stadtpark-und-volkspark\")\n\n# now, let's do a more specific search for specific resources (we look at Kinder = kids/ children)\nx <- resource_search(q = \"name:Kinder\", limit = 3)\nx$results\n\n# here you get the name, the Description (not always filled out) and the data format\n\n# now we want to have a closer look at the second resource (day care for children)\n# we need to get the url, by using the resource number\n\nurl<-resource_show(id =\"a8413550-bf4d-40f3-921a-941da3fce132\")\nurl$url\n\n# with the url, we can now import the data\nurl <- (\"https://geo.sv.rostock.de/download/opendata/kindertagespflegeeinrichtungen/kindertagespflegeeinrichtungen.csv\")\ndestfile <- (\"kindertagespflegeeinrichtungen.csv\")\ncurl::curl_download(url, destfile)\n\nkindertagespflegeeinrichtungen <- read_csv(destfile)\nView(kindertagespflegeeinrichtungen)\n\n# in this file, you can now for example look at the opening hours of the day cares in Rostock (a German city)"},{"path":"ckan-api.html","id":"social-science-examples-8","chapter":"11 CKAN API","heading":"11.5 Social science examples","text":"social science research examples using API?looking social science research used CKAN API Open Government data (OGD), seems papers research usage data, data (@Bedini2014, @Correa2015).\nrecent paper examines use OGD (@Quarati2019-jf), authors come conclusion, one hand many OGD portals lack information data usage, hand, information can found, becomes obvious data rarely used.\nexample, regarding German OGD portal “GovData.de”, find social science papers specifically used data GovData.de. However, papers available describe German open data initiative (@Liu2018) metadata (@Marienfeld2013) can found GovData.de.","code":""},{"path":"mediawiki-action-api.html","id":"mediawiki-action-api","chapter":"12 MediaWiki Action API","heading":"12 MediaWiki Action API","text":"Noam Himmelrath, Jacopo Gambato","code":""},{"path":"mediawiki-action-api.html","id":"provided-servicesdata-10","chapter":"12 MediaWiki Action API","heading":"12.1 Provided services/data","text":"data/service provided API?\naccess Wikipedia, MediaWiki provides MediaWiki Action API.API can used multiple things, accessing wiki features, interacting wiki obtaining meta-information wikis public users. Additionally, web service can provide access data post changes Wikipedia-webpages.","code":""},{"path":"mediawiki-action-api.html","id":"prerequesites-10","chapter":"12 MediaWiki Action API","heading":"12.2 Prerequesites","text":"prerequisites access API (authentication)? pre-registration required access API. However, certain actions, large queries, registration required. Moreover, hard fast limit read requests, system administrators heavily recommend limiting request rate secure stability side. also best practice set descriptive User Agent header.","code":""},{"path":"mediawiki-action-api.html","id":"simple-api-call-10","chapter":"12 MediaWiki Action API","heading":"12.3 Simple API call","text":"simple API call look like?mentioned, API can used communicate Wikipedia variety actions. likely social scientist extract information rather post changes Wikipedia page, focus obtaining Wikipedia information need.include basic API call obtain information Albert Einstein Wikipedia pagehttps://en.wikipedia.org/w/api.php?action=query&format=json&prop=info&titles=Albert%20Einsteinto plugged search bar browser obtain basic information page.Notice first line common calls API, second line relates specific action trying perform.","code":""},{"path":"mediawiki-action-api.html","id":"api-access-10","chapter":"12 MediaWiki Action API","heading":"12.4 API access","text":"can access API R (httr + packages)?common tool WikipediR, wrapper around Wikipedia API. allows R access information “directions” relevant page pages Wikipedia content metadata therein. Importantly, wrapper allows gather information, implies instrument needs accompanied packages rvest scraping XML jsonlite parsing.report code obtain information previous example R:","code":"\nWikipediR::page_info(\n    language = \"en\", \n    project = \"wikipedia\", \n    page = \"Albert Einstein\", \n    properties = \"url\")## $batchcomplete\n## [1] \"\"\n## \n## $query\n## $query$pages\n## $query$pages$`736`\n## $query$pages$`736`$pageid\n## [1] 736\n## \n## $query$pages$`736`$ns\n## [1] 0\n## \n## $query$pages$`736`$title\n## [1] \"Albert Einstein\"\n## \n## $query$pages$`736`$contentmodel\n## [1] \"wikitext\"\n## \n## $query$pages$`736`$pagelanguage\n## [1] \"en\"\n## \n## $query$pages$`736`$pagelanguagehtmlcode\n## [1] \"en\"\n## \n## $query$pages$`736`$pagelanguagedir\n## [1] \"ltr\"\n## \n## $query$pages$`736`$touched\n## [1] \"2021-12-05T18:46:13Z\"\n## \n## $query$pages$`736`$lastrevid\n## [1] 1058773374\n## \n## $query$pages$`736`$length\n## [1] 183211\n## \n## $query$pages$`736`$fullurl\n## [1] \"https://en.wikipedia.org/wiki/Albert_Einstein\"\n## \n## $query$pages$`736`$editurl\n## [1] \"https://en.wikipedia.org/w/index.php?title=Albert_Einstein&action=edit\"\n## \n## $query$pages$`736`$canonicalurl\n## [1] \"https://en.wikipedia.org/wiki/Albert_Einstein\"\n## \n## \n## \n## \n## attr(,\"class\")\n## [1] \"pageinfo\""},{"path":"mediawiki-action-api.html","id":"social-science-examples-9","chapter":"12 MediaWiki Action API","heading":"12.5 Social science examples","text":"social science research examples using API?papers using Wikipedia-information rely API access data. papers cover wide range social economical sciences. Political science papers , example, concerned political elections, specifically election prediction [@margolin2016wiki; @salem2021wikipedia]. papers use data accessed API analyze media coverage COVID-19 pandemic [@gozzi2020collective] interplay online information investment markets [@elbahrawy2019wikipedia].","code":""},{"path":"references.html","id":"references","chapter":"13 References","heading":"13 References","text":"","code":""}]
