library(pagedown)
library(tidyverse)
library(googleLanguageR)
library(tidytext)
library(ggwordcloud)
# Authentication (through your service account's JSON key file)
gl_auth("C:/Users/Paul/Google Drive/2-Teaching/2021 Computational Social Science/keys/css-seminar-2021-a1e75382ae2c.json")
data_syntax <- gl_nlp(data_tweets$translatedText, nlp_type = "analyzeSyntax")
load("C:/Users/Paul/Google Drive/2-Teaching/2021 Computational Social Science/2021_computational_social_science/data/data_tweets.RData")
library(tidyverse)
library(googleLanguageR)
library(tidytext)
library(ggwordcloud)
# Authentication (through your service account's JSON key file)
gl_auth("C:/Users/Paul/Google Drive/2-Teaching/2021 Computational Social Science/keys/css-seminar-2021-a1e75382ae2c.json")
# Load data
load("C:/Users/Paul/Google Drive/2-Teaching/2021 Computational Social Science/2021_computational_social_science/data/data_tweets.RData")
# Call the API via the function 'gl_nlp()' and specify your quantity of interest (here: analyzeSyntax)
data_syntax <- gl_nlp(data_tweets$translatedText, nlp_type = "analyzeSyntax")
data_tweets$syntax_tokens <- data_syntax[["tokens"]]
data_syntax
gl_translate(data_tweets$text, target ="en")
gl_translate(data_tweets$text, target ="en")gl_translate(data_tweets$text, target ="en")$translatedText
gl_translate(data_tweets$text, target ="en")$translatedText
bind_cols(data_tweets,
text_en = gl_translate(data_tweets$text, target ="en")$translatedText)
data_tweets <-
bind_cols(data_tweets,
text_en = gl_translate(data_tweets$text,
target ="en")$translatedText)
data_syntax <- gl_nlp(data_tweets$test_en, nlp_type = "analyzeSyntax")
names(data_tweets)
setwd("C:/Users/camil/Desktop/apis_for_social_scientists_a_review")
getwd()
